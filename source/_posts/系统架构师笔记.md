---
title: 系统架构师笔记(施工中)
date: 2020-12-24 10:08:59
categories: 读书笔记
tags: [读书笔记]
---
# 第一章 计算机组成与体系结构
## 1.1 计算机系统组成
###  1.1.1 计算机硬件的组成  
&emsp;&emsp;计算机系统由`运算器，控制器，存储器，输入设备，输出设备`五部分组成。

1. 控制器  
&emsp;&emsp;控制器是分析和执行指令的部件，也是统一指挥并控制计算机各部件协调工作的中心部件，所依据的是机器指令。

控制器的组成包含：

* 程序计数器`PC`：存储下一条要执行指令的地址。
* 指令寄存器`IR`：存储即将执行的指令。
* 指令译码器`ID`：对指令中的操作码字段进行分析解释。
* 时序部件：提供时序控制信号。

2. 运算器  
&emsp;&emsp;运算器也称为算术逻辑单元（ArithmeticandLogicUnit，ALU），其主要功能是在控制器的控制下完成各种算术运算和逻辑运算。 

运算器的组成包含：

* 算术逻辑单元`ALU`：数据的算术运算和逻辑运算。
* 累加寄存器`AC`：通用寄存器，为ALU提供一个工作区，用于暂存数据。
* 数据缓冲寄存器`DR`：写内存时，暂存指令或数据。
* 状态条件寄存器`PSW`：存状态标志与控制标志（争议点：也有将其归为控制器的）。

3. 主存储器  
&emsp;&emsp;主存储器也称为内存储器（通常简称为“内存”或“主存”）。存储现场操作的信息与中间结果，包括机器指令和数据。  

4. 辅助存储器  
&emsp;&emsp;辅助存储器也称为外存储器，通常简称为外存或辅存。存储需要长期保存的各种信息。

5. 输入设备  
&emsp;&emsp;输入设备的任务是把人们编好的程序和原始数据送到计算机中去,并且将它们转换成计算机内部所能识别和接受的信息方式。按输入信息的形态可分为字符（包括汉字）输入、图形输入、图像输入及语音输入等。目前，常见的输入设备有键盘、鼠标、扫描仪等。

6. 输出设备  
&emsp;&emsp;输出设备的任务是将计算机的处理结果以人或其他设备所能接受的 形式送出计算机。目前，最常用的输出设备是打印机和显示器。有些设备既可以是输入设备，同时也可以是输出设备，例如，辅助存储器、自动控制和检测系统中使用的数模转换装置等。

### 1.1.2 计算机系统结构的分类
#### 1.存储程序的概念
&emsp;&emsp;“存储程序”由冯·诺依曼提出，是计算机的系统架构，符合存储程序概念的计算机统称为冯·诺依曼型计算机。它的基本含义有以下三点：  

* 计算机由运算器、存储器、控制器、输入设备、输出设备5部分组成。
* 计算机内部由二进制来表示指令和数据。
* 将编好的程序和数据事先存入存储器中，然后再启动计算机工作。

#### 2. Flynn分类
&emsp;&emsp;1966年，Michael.J.Flynn提出根据`指令流`、`数据流`的多倍性特征对计算机系统进行分类（通常称为 Flynn 分类法）。  

* 指令流：指机器执行的指令序列
* 数据流：指由指令流调用的数据序列，包括输入数据和中间结果，但不包括输出数据。  

&emsp;&emsp;Flynn根据不同的指令流-数据流组织方式，把计算机系统分成以下四类：

1. 单指令流单数据流（Single Instruction stream and Single Data stream，`SISD`）  
&emsp;&emsp;SISD其实就是传统的顺序执行的单处理器计算机，其指令部件每次只对一条指令进行译码，并只对一个操作部件分配数据。  
2. 单指令流多数据流（Single Instruction stream and Multiple Data stream，`SIMD`）  
&emsp;&emsp;SIMD以并行处理机（矩阵处理机）为代表，并行处理机包括多个重复的处理单元，由单一指令部件控制，按照同一指令流的要求为它们分配各自所需的不同数据。  
3. 多指令流单数据流（Multiple Instruction stream and Single Data stream，`MISD`）  
&emsp;&emsp;MISD具有多个处理单元，按多条不同指令的要求对同一数据流及其中间结果进行不同的处理。一个处理单元的输出又作为另一个处理单元的输入。这类系统实际上很少见到。有文献把流水线看作多个指令部件，称流水线计算机是 MISD。
4. 多指令流多数据流（Multiple Instruction stream and Multiple Data stream，`MIMD`）  
&emsp;&emsp;MIMD是指能实现作业、任务、指令等各级全面并行的多机系统。如多核处理器、多处理机等。

### 1.1.3 复杂指令集系统与精简指令集系统
&emsp;&emsp;一个处理器支持的指令和指令的字节级编码成为其指令集体系结构，有CISC和RISC两种发展途径。

#### 1. CISC
&emsp;&emsp;CISC(Complex Instruction Set Computer)全称是复杂指令系统计算机，它的基本思想是进一步增强其原有指令的功能，用更为复杂的新指令取代原先由软件子程序完成的功能。`目前使用的绝大多数计算机都属于CISC类型`。  

&emsp;&emsp;CSIC的特点如下：

1. 指令数量众多  
&emsp;&emsp;指令系统拥有大量的指令，通常有 100～250 条。  
2. 指令使用频率相差悬殊  
&emsp;&emsp;最常使用的是一些比较简单的指令，仅占指令总数的20%，但在程序中出现的频率却占80%。而大部分复杂指令却很少使用。  
3. 支持多种寻址方式  
&emsp;&emsp;支持的寻址方式通常为 5～20 种。  
4. 变长的指令  
&emsp;&emsp;指令长度不是固定的，变长的指令增加指令译码电路的复杂性。  
5. 指令可以对主存单元中的数据直接进行处理  
&emsp;&emsp;典型的 CISC 通常都有指令能够直接对主存单元中的数据进行处理，`但其执行速度较慢`。  
6. 以微程序控制为主  
&emsp;&emsp;CISC的指令系统很复杂，难以用硬布线逻辑（组合逻辑）电路实现控制器，通常采用微程序控制。

#### 2. RISC
&emsp;&emsp;RISC(Reduced Instruction Set Computer)全称是精简指令系统计算机。它的基本思想是通过减少指令总数和简化指令功能降低硬件设计的复杂度，使指令能单周期运行，并通过优化编译提高指令的执行速度，采用硬布线逻辑优化编译程序。

&emsp;&emsp;RISC的特点如下：

1. 指令数量少  
&emsp;&emsp;优先选取使用频率最高的一些简单指令和一些常用指令，避免使用复杂指令。只提供了LOAD（从存储器中读数）和STORE（把数据写入存储器）两条指令对存储器操作，其余所有的操作都在 CPU 的寄存器之间进行。  
2. 指令的寻址方式少  
&emsp;&emsp;通常只支持寄存器寻址方式、立即数寻址方式和相对寻址方式。  
3. 指令长度固定，指令格式种类少  
&emsp;&emsp;因为 RISC 指令数量少、格式少、相对简单，其指令长度固定，指令之间各字段的划分比较一致，译码相对容易。  
4. 以硬布线逻辑控制为主  
&emsp;&emsp;为了提高操作的执行速度，通常采用硬布线逻辑（组合逻辑）来构建控制器。  
5. 单周期指令执行  
&emsp;&emsp;因为简化了指令系统，很容易利用流水线技术，使得大部分指令都能在一个机器周期内完成。少数指令可能会需要多周期，例如LOAD/STORE 指令因为需要访问存储器，其执行时间就会长一些。  
6. 优化的编译器  
&emsp;&emsp;RISC的精简指令集使编译工作简单化。因为指令长度固定、格式少、寻址方式少，编译时不必在具有相似功能的许多指令中进行选择，也不必为寻址方式的选择而费心，同时易于实现优化，从而可以生成高效率执行的机器代码。
7. CPU中的通用寄存器数量多  
&emsp;&emsp;一般在32个以上，有的可达上千个。

### 1.1.4 总线

&emsp;&emsp;总线是一组能为多个部件分时共享的公共信息传送线路。共享是指总线上可以挂接多个部件，各个部件之间相互交换的信息都可以通过这组公共线路传送；分时是指同一时刻只允许有一个部件向总线发送信息，如果出现两个或两个以上部件同时向总线发送信息，势必导致信号冲突。当然，在同一时刻，允许多个部件同时从总线上接收相同的信息。  
&emsp;&emsp;按总线相对于 CPU 或其他芯片的位置可分为`内部总线`和`外部总线`两种。在 CPU 内部，寄存器之间和算术逻辑部件ALU与控制部件之间传输数据所用的总线称为内部总线；外部总线是指CPU与内存RAM、ROM和输入/输出设备接口之间进行通信的通路。由于CPU通过总线实现程序取指令、内存/外设的数据交换，在 CPU 与外设一定的情况下，`总线速度是制约计算机整体性能的最大因素`。  
&emsp;&emsp;按总线功能来划分，又可分为`地址总线`、`数据总线`、`控制总线`三类，人们通常所说的总线都包括这三个组成部分，地址总线用来传送地址信息，数据总线用来传送数据信息，控制总线用来传送各种控制信号。

## 1.2 存储器系统
 
&emsp;&emsp;传统的存储器系统一般分为`高速缓冲存储器（Cache）`、`主存`、`辅存`三级。主存可由CPU直接访问，存取速度快，但容量较小，一般用来存放当前正在执行的程序和数据。辅存设置在主机外部，它的存储容量大，价格较低，但存取速度较慢，一般用来存放暂时不参与运行的程序和数据，CPU 不可以直接访问辅存，辅存中的程序和数据在需要时才传送到主存，因此它是主存的补充和后援。当 CPU 速度很高时，为了使访问存储器的速度能与 CPU 的速度相匹配，又在主存和 CPU 间增设了一级 Cache。Cache 的存取速度比主存更快，但容量更小，用来存放当前最急需处理的程序和数据，以便快速地向 CPU 提供指令和数据。因此，计算机采用多级存储器体系，确保能够获得尽可能高的存取速率，同时保持较低的成本。

&emsp;&emsp;存储器中数据常用的存取方式有`顺序存取`、`直接存取`、`随机存取`和`相联存取`四种。
1. 顺序存取  
&emsp;&emsp;存储器的数据以记录的形式进行组织。对数据的访问必须按特定的线性顺序进行。磁带存储器采用顺序存取的方式。
2. 直接存取  
&emsp;&emsp;与顺序存取相似，直接存取也使用一个共享的读写装置对所有的数据进行访问。但是，每个数据块都拥有唯一的地址标识，读写装置可以直接移动到目的数据块所在位置进行访问。存取时间也是可变的。磁盘存储器采用直接存取的方式。
3. 随机存取  
&emsp;&emsp;存储器的每一个可寻址单元都具有自己唯一的地址和读写装置，系统可以在相同的时间内对任意一个存储单元的数据进行访问，而与先前的访问序列无关。主存储器采用随机存取的方式。
4. 相联存取  
&emsp;&emsp;相联存取也是一种随机存取的形式，但是选择某一单元进行读写是取决于其内容而不是其地址。与普通的随机存取方式一样，每个单元都有自己的读写装置，读写时间也是一个常数。使用相联存取方式，可以对所有的存储单元的特定位进行比较，选择符合条件的单元进行访问。为了提高地址映射的速度，Cache 采取相联存取的方式。
    
### 1.2.1 主存储器
&emsp;&emsp;主存用来存放计算机运行期间所需要的程序和数据，CPU可直接随机地进行读/写。主存具有一定容量，存取速度较高。由于CPU要频繁地访问主存，所以主存的性能在很大程度上影响了整个计算机系统的性能。根据工艺和技术不同，主存可分为`随机存取存储器`和`只读存储器`。

#### 1.随机存取存储器
&emsp;&emsp;随机存取存储器（Random Access Memory，RAM）既可以写入也可以读出，但断电后信息无法保存，因此只能用于暂存数据。RAM又可分为DRAM（Dynamic RAM，动态RAM）和SRAM（Static RAM，静态RAM）两种，DRAM 的信息会随时间逐渐消失，因此需要定时对其进行刷新维持信息不丢失；SRAM 在不断电的情况下信息能够一直保持而不会丢失。DRAM 的密度大于 SRAM 且更加便宜，但 SRAM 速度快，电路简单（不需要刷新电路），然而容量小，价格高。
#### 2.只读存储器
&emsp;&emsp;只读存储器（Read Only Memory，ROM）可以看作 RAM 的一种特殊形式，其特点是存储器的内容只能随机读出而不能写入。这类存储器常用来存放那些不需要改变的信息。由于信息一旦写入存储器就固定不变了，即使断电，写入的内容也不会丢失，所以又称为固定存储器。ROM 一般用于存放系统程序 BIOS（Basic Input Output System，基本输入输出系统）。
#### 3.内存编址方法
&emsp;&emsp;在计算机系统中，存储器中每个单元的位数是相同且固定的，称为存储器编址单位。不同的计算机，存储器编址的方式不同，主要有字编址和字节编址。  
&emsp;&emsp;内存一般以字节（8 位）为单位，或者以字为单位（字的长度可大可小，例如 16 位或者 32 位等，在这类试题中，一般会给出字的大小）。
```
例如，内存地址从 AC000H 到 C7FFFH
则共有C7FFFFH-AC000H+1=1C000H 个地址单元

转换为10进制则有 
 12*16^3+1*16^4
=12*2^12+1*2^16
=12*2^2KB+1*2^6KB
=112KB

如果该内存地址按字（16bit）编址，则共有 112KB*16 位。
假设该内存由 28 片存储器芯片构成，已知构成此内存的芯片每片有 16KB 个存储单元，则该芯片每个存储单元存储
（112KB*16）/（28*16KB）=4 位。
```

### 1.2.2 辅助存储器
#### 1．磁带存储器
&emsp;&emsp;磁带存储器是一种顺序存取的设备，其特点包括：存取时间较长，但存储容量大，便于携带，价格便宜。磁带应用的场景越来越少，目前主要用于资料的归档保存。
#### 2．硬盘存储器
&emsp;&emsp;在硬盘中，信息分布呈以下层次：`记录面`、`圆柱面`、`磁道`和`扇区`，如图所示。 

[![硬盘信息分布示意图](https://s3.ax1x.com/2020/12/24/rg5IJJ.png)](https://imgchr.com/i/rg5IJJ)

&emsp;&emsp;一台硬盘驱动器中有多个磁盘片，每个盘片有两个记录面，每个记录面对应一个磁头，所以`记录面号就是磁头号`，如图中（a）所示。    
&emsp;&emsp;所有的磁头安装在一个公用的传动设备或支架上，磁头一致地沿盘面径向移动，`单个磁头不能单独地移动`。在记录面上，一条条磁道形成一组同心圆，最外圈的磁道为 0 号，往内则磁道号逐步增加，如图中（b）所示。通常将一条磁道划分为若干个段，每个段称为一个扇区或扇段，每个扇区存放一个定长信息块（例如，512 个字节）。一条磁道划分多少扇区，每个扇区可存放多少字节，一般由操作系统决定。磁道上的扇区编号从 1 开始，不像磁头或柱面编号从 0开始。    
&emsp;&emsp;在一个盘组中，各记录面上相同编号（位置）的各磁道构成一个柱面，如图中（c）所示。若每个磁盘片有 m 个磁道，则该硬盘共有 m 个柱面。引入柱面的概念是为了提高硬盘的存储速度。当主机要存入一个较大的文件时，若一条磁道存不完，就需要存放在几条磁道上。这时，应首先将一个文件尽可能地存放在同一柱面中。如果仍存放不完，再存入相邻的柱面内。

&emsp;&emsp;在磁盘上进行信息的读写时，首先需要定位到目标磁道，这个过程称之为`寻道`，寻道所消耗的时间称为`寻道时间`。定位到目标磁道后，需要定位到目标扇区，此过程通过旋转盘片完成，平均旋转`半圈`可到目标位置。故磁盘访问时间为：`磁盘访问时间（存取时间） = 寻道时间+旋转延迟时间`

### 1.2.3 Cache存储器
&emsp;&emsp;Cache 通常采用相联存储器（ContentAddressable Memory，CAM）。CAM 是一种基于数据内容进行访问的存储设备。当对其写入数据时，CAM 能够自动选择一个未用的空单元进行存储；当要读出数据时，不是给出其存储单元的地址，而是直接给出该数据或者该数据的一部分内容，CAM 对所有存储单元中的数据同时进行比较，并标记符合条件的所有数据以供读取。由于比较是同时、并行进行的，所以，这种基于数据内容进行读写的机制，其速度比基于地址进行读写的方式要快很多。
#### 1．Cache基本原理
&emsp;&emsp;使用 Cache 改善系统性能的依据是程序的`局部性原理`。

&emsp;&emsp;局部性原理是指程序在执行时呈现出局部性规律，即在一较短的时间内，程序的执行仅局限于某个部分。相应地，它所访问的存储空间也仅局限于某个区域。

&emsp;&emsp;根据程序的局部性原理，可以把目前常用或将要用到的信息预先放在 Cache 中。当CPU 需要读取数据时，首先在 Cache 中查找是否有所需内容，如果有，则直接从 Cache 中读取；若没有，再从内存中读取该数据，然后同时送往 CPU 和 Cache。如果 CPU 需要访问的内容大多都能在 Cache 中找到（称为`访问命中`），则可以大大提高系统性能。

&emsp;&emsp;如果以 h 代表对 Cache 的访问命中率（“1-h”称为失效率，或者称为未命中率），t1 表示 cache 的周期时间，t2 表示内存的周期时间，以读操作为例，使用“Cache+主存储器”的系统的平均周期为 t3。则：
>t3=t1\*h+t2\*(1-h)

&emsp;&emsp;系统的平均存储周期与命中率有很密切的关系，命中率的提高即使很小也能导致性能上的较大改善。

```
设某计算机主存的读/写时间为 l00ns，有一个指令和数据合一的Cache
已知该Cache的读/写时间为 10ns，取指令的命中率为 98%，取数的命中率为 95%
在执行某类程序时，约有 1/5 指令需要存/取一个操作数。
假设指令流水线在任何时候都不阻塞，则设置 Cache 后，每条指令的平均访存时间约为：
(2%*100ns+98%*10ns)+1/5*(5%*100ns+95%*10ns)=14.7ns
```

#### 2. 映射机制
&emsp;&emsp;当 CPU 发出访存请求后，存储器地址先被送到 Cache 控制器以确定所需数据是否已在 Cache 中，若命中则直接对 Cache 进行访问。这个过程称为 Cache 的地址映射（映像）。  
&emsp;&emsp;在 Cache 的地址映射中，主存和 Cache 将均分成容量相同的块（页）。常见的映射方法有`直接映射`、`全相联映射`和`组相联映射`。

1. 直接映射  

&emsp;&emsp;直接映射以随机存取存储器作为 Cache 存储器，硬件电路较简单。在进行映射时，主存地址被分成三个部分，从高到低依次为：区号、页号以及页内地址，如图所示。  

[![直接映射方式的主存地址](https://s3.ax1x.com/2020/12/24/rgq5Bn.png)](https://imgchr.com/i/rgq5Bn)

&emsp;&emsp;在本例中，内存容量为 1GB，Cache 容量为 8MB，页面的大小为 512KB。直接映射中先分区，再分页。一个区的大小就是 Cache 容量的大小，所以一共分：1GB/8MB=128 个区，区号7位。每个区分：8MB/512KB=16个页，所以页号为 4 位。  

&emsp;&emsp;在直接映射方式中，每个主存页只能复制到某一固定的 Cache 页中，如下图所示。直接映射方式的映射规律是：主存中每个区的第 0 页，只能进入到 Cache 的第 0 页。即：若当前时刻 Cache 中 0 号页已被占据，而 1-15 号页空闲，现在要将 1 区第 0 页（即内存的 16 页）调入 Cache 是会发生冲突的。所以直接映射的块冲突率非常高。

[![直接映射方式](https://s3.ax1x.com/2020/12/24/rgLwCT.png)](https://imgchr.com/i/rgLwCT)

&emsp;&emsp;由于每个区的 N 号页，都必须进入到 Cache 的 N 号页，所以只需要记录区号即可。

2. 全相联映射

&emsp;&emsp;全相联映射使用相联存储器组成Cache存储器。在全相联映射方式中，主存的每一页可以映射到Cache的任一页。如果淘汰Cache中某一页的内容，则可调入任一主存页的内容，因而较直接映射方式灵活。  
&emsp;&emsp;在全相联映射方式中，主存地址分为两个部分，分别为地址部分（主存页标记）和数据部分（页内地址）。数据部分用于存放数据，而地址部分则存放该数据的存储器地址。如图所示。

[![主存储示例](https://s3.ax1x.com/2020/12/24/rgjuU1.png)](https://imgchr.com/i/rgjuU1)

&emsp;&emsp;当进行映射时，在我们给定的例子中，当程序访存时，则高 11 位给出主存页号，低19 位给出页内地址。因为每个 Cache 页可映射到 2048 个主存页中的任一页，所以每页的Cache 标记也需要 11 位，以表明它现在所映射的主存页号。因此，Cache 标记信息位数增加，比较逻辑成本随之增加。  
&emsp;&emsp;在全相联映射方式中，主存地址不能直接提取 Cache 页号，而是需要将主存页标记与Cache 各页的标记逐个比较，直到找到标记符合的页（访问 Cache 命中），或者全部比较完后仍无符合的标记（访问 Cache 失败）。因此`这种映射方式速度很慢，失掉了高速缓存的作用，这是全相联映射方式的最大缺点`。如果让主存页标记与各 Cache 标记同时比较，则成本又太高。全相联映射方式因比较器电路难于设计和实现，只适用于小容量 Cache。

3. 组相联映射

&emsp;&emsp;组相联映射（页组映射）介于直接映射和全相联映射之间，是这两种映射的一种折衷方案。全相联映射方式以页为单位，可自由映射，没有固定的对应关系。直接映射方式中，主存分组，主存组内的各页与 Cache 的页之间采取的是固定的映射关系，但各组均可映射到Cache 中。在组相联映射方式中，主存与 Cache 都分组，主存中一个组内的页数与 Cache 的分组数相同，如图所示。

[![组相连映射方式](https://s3.ax1x.com/2020/12/24/rgjLI1.png)](https://imgchr.com/i/rgjLI1)

&emsp;&emsp;在上图给出的例子中，主存分 128 个区，每个区 8 个组，每个组 2 个页。组相联映射方式的主存地址组织如下图所示。

[![组相联映射主存地址示例](https://s3.ax1x.com/2020/12/24/rgvGWV.png)](https://imgchr.com/i/rgvGWV)

&emsp;&emsp;组相联映射的规则是：主存中的组与 Cache 的组形成直接映射关系，而每个组内的页是全相联映射关系。如主存 1 区 0 页，他在 0 组中，所以只能进入 Cache 的 0 组中，至于进入到 Cache 的 0 组 0 页，还是 0 组 1 页，并无强制要求，可任意放置。  
&emsp;&emsp;在组相联映射中，Cache 中每一页的标记位长度为 8 位，因为此时除了要记录区号，还得记录组号，即区号 7 位加组号 1 位等于 8 位。
在组相联映射中，由于 Cache 中每组有若干可供选择的页，因而它在映射定位方面较直接映射方式灵活；每组页数有限，因此付出的代价不是很大，可以根据设计目标选择组内页数。

#### 3. 替换算法

&emsp;&emsp;当 Cache 产生了一次访问未命中之后，相应的数据应同时读入 CPU 和 Cache。但是当Cache 已存满数据后，新数据必须替换（淘汰）Cache 中的某些旧数据。最常用的替换算法有以下三种：
1. 随机算法  
&emsp;&emsp;这是最简单的替换算法。随机法完全不管 Cache 块过去、现在及将来的使用情况，简单地根据一个随机数，选择一块替换掉。
2. 先进先出（First In and First Out，FIFO）算法    
&emsp;&emsp;按调入 Cache 的先后决定淘汰的顺序，即在需要更新时，将最先进入 Cache 的块作为被替换的块。这种方法要求为每块做一记录，记下它们进入 Cache 的先后次序。这种方法容易实现，而且系统开销小。其缺点是`可能会把一些需要经常使用的程序块（如循环程序）替换掉`。
3. 近期最少使用（Least Recently Used，LRU）算法  
&emsp;&emsp;LRU 算法是把 CPU 近期最少使用的块作为被替换的块。这种替换方法需要随时记录 Cache 中各块的使用情况，以便确定哪个块是近期最少使用的块。LRU 算法相对合理，但实现起来比较复杂，系统开销较大。通常需要对每一块设置一个称为“年龄计数器”的硬件或软件计数器，用以记录其被使用的情况。

#### 4．写操作
&emsp;&emsp;因为需要保证缓存在 Cache 中的数据与内存中的内容一致，相对读操作而言，Cache 的写操作比较复杂，常用的有以下几种方法。
1. 写直达（write through）  
&emsp;&emsp;当要写 Cache 时，数据同时写回内存，有时也称为写通。当某一块需要替换时，也不必把这一块写回到主存中去，新调入的块可以立即把这一块覆盖掉。这种方法实现简单，而且能随时保持主存数据的正确性，但`可能增加多次不必要的主存写入`，会降低存取速度。
2. 写回（write back）  
&emsp;&emsp;CPU 修改 Cache 的某一块后，相应的数据并不立即写入内存单元，而是当该块从 Cache 中被淘汰时，才把数据写回到内存中。在采用这种更新策略的Cache块表中，一般有一个标志位，当一块中的任何一个单元被修改时，标志位被置“1”。  
&emsp;&emsp;在需要替换掉这一块时，如果标志位为“1”，则必须先把这一块写回到主存中去之后，才能再调入新的块；如果标志位为“0”，则这一块不必写回主存，只要用新调入的块覆盖掉这一块即可。这种方法的优点是`操作速度快`，缺点是`因主存中的字块未随时修改而有可能出错`。
3. 标记法  
&emsp;&emsp;对 Cache 中的每一个数据设置一个有效位。当数据进入 Cache 后，有效位置“1”；而当 CPU 要对该数据进行修改时，数据只需写入内存并同时将该有效位置“0”。当要从 Cache 中读取数据时需要测试其有效位，若为“l”则直接从 Cache 中取数，否则，从内存中取数。

## 1.3 流水线
&emsp;&emsp;流水线技术把一个任务分解为若干顺序执行的子任务，不同的子任务由不同的执行机构负责执行，而这些机构可以`同时并行工作`。在任一时刻，任一任务只占用其中一个执行机构，这样就可以实现多个任务的重叠执行，以提高工作效率。
### 1.3.1 流水线周期
&emsp;&emsp;流水线应用过程中，会将需要处理的工作分为 N 个阶段，`最耗时的那一段所消耗的时间为流水线周期`。如：使用流水线技术执行 100 条指令，每条指令取指 2ms，分析 4ms，执行 1ms，则流水线周期为 4ms。
### 1.3.2 计算流水线执行时间
&emsp;&emsp;延续上面的场景，将 1 个任务的执行过程可分成 N 个阶段，假设每个阶段完成时间为 t，则完成该任务所需的时间即为 Nt。若以传统的方式，则完成 k 个任务所需的时间是kNt；而使用流水线技术执行，且花费的时间是 Nt+(k-1)t。也就是说，除了第 1 个任务需要完整的时间外，其他都通过并行，节省下了大量的时间。所以流水线的执行时间可通俗的表达为：
>流水线执行时间=第 1 条指令的执行时间+（n-1）\*流水线周期   
注：n 代表需要处理的任务数量。

```
    在考试时，又需要特别注意一个细节问题。
    流水线的执行时间计算，其实进一步可以分理论情况与实践情况两种不同的处理方式。
例：
    某计算机系统，一条指令的执行需要经历取指（2ms）、分析（4ms）、执行（1ms）三个阶段，现要执行 100 条指令，利用流水线技术需要多长时间?
    理论上来说，1 条指令的执行时间为：2ms+4ms+1ms=7ms。
    所以：理论流水线执行时间=2ms+4ms+1ms+(100-1)*4=403ms。
    而实际上，真正做流水线处理时，考虑到处理的复杂性，会将指令的每个执行阶段的时间都统一为流水线周期，即 1 条指令的执行时间为：4ms+4ms+4ms=12ms。 
    所以：实际流水线执行时间=4ms+4ms+4ms+(100-1)*4=408ms。

    考试时 80%以上的概率采用理论公式计算，所以考试时需要以理论公式计算，若计算的结果无正确选项才考虑采用实际公式计算。
```
### 1.3.3 流水线的吞吐率
&emsp;&emsp;流水线的吞吐率（Though Put rate，TP）是指在`单位时间`内`流水线所完成的任务数量或输出的结果数量`。有些文献也称为平均吞吐率、实际吞吐率。  
&emsp;&emsp;计算流水线吞吐率的最基本的公式如下：
$$ 
TP=\frac {n} {T_k} 
$$
&emsp;&emsp;其中n为任务数量，$T_k$是处理完成n个任务所用的时间

&emsp;&emsp;流水线的最大吞吐率为：

$$TP_{max}=\lim_{n \to \infty} \frac n {(k+n-1)\Delta t}=\frac 1 {\Delta t} $$

### 1.3.4 流水线的加速比
&emsp;&emsp;在流水线中，因为在同一时刻，有多个任务在重叠地执行，虽然完成一个任务的时间与单独执行该任务相近（甚至由于分段的缘故，可能更多一些），但是从整体上看完成多个任务所需的时间则大大减少。  
&emsp;&emsp;完成同样一批任务，`不使用流水线所用的时间`与`使用流水线所用的时间`之比称为流水线的加速比（speedup ratio）。如果不使用流水线，即顺序执行所用的时间为 T0 ，使用流水线的执行时间为 Tk ，则计算流水线加速比的基本公式如下：

$$ S=\frac {T_0} {T_k} $$

&emsp;&emsp;如果流水线各个流水段的执行时间都相等（设为 Dt），则一条 k 段流水线完成 n 个连续任务所需要的时间为(k+n-1)Dt。如果不使用流水线，即顺序执行这 n 个任务，则所需要的时间为 nkDt。  
&emsp;&emsp;因此，各个流水段执行时间均相等的一条 k 段流水线完成 n 个连续任务时的实际加速比为：

$$ S=\frac {nk\Delta t} {(k+n-1)\Delta t}=\frac {nk} {k+n-1}$$

&emsp;&emsp;这种情况下的最大加速比为：

$$ S_{max}=\lim_{n \to \infty} \frac {nk} {k+n-1}=k$$



<!-- 

### 1.1.3 数据表示
1. 原码  
如果机器字长为n，那么原码的定义如下：  
若X是纯整数，则当X是非负数时原码即为X，当X是负数是原码为2^(n-1) + |X|。  
若X是纯小数，则当X是非负数时原码即为X，当X是负数时原码为2^0 + |X|。  
`负数首位为1`
2. 反码
如果机器字长为n，那么反码的定义如下：  
若X是纯整数，则当X是非负数时原码即为X，当X是负数是原码为2^n - 1 + |X|。  
若X是纯小数，则当X是非负数时原码即为X，当X是负数时原码为2-2^-(n-1) + |X|。  
`负数按位取反`
3. 补码
如果机器字长为n，那么补码的定义如下：  
若X是纯整数，则当X是非负数时原码即为X，当X是负数是原码为2^n + |X|。  
若X是纯小数，则当X是非负数时原码即为X，当X是负数时原码为2 + |X|。 
`负数按位取反+1`
4. 移码
在机器字长为n，偏移量为2^(n-1)的情况下，纯整数的移码为2^(n-1)+X,纯小数的移码为1+X。`补码符号位取反即可得到移码`  

### 1.1.4 校验码
计算机通常使用校验码的方法来检测传送的数据是否出问题。  
`码距`:一个编码系统中任意两个合法编码之间至少有多少个二进制位不同  
1. 奇偶校验码  
通过在编码中增加一位校验位来使编码中1的个数为奇数（奇校验）或者偶数（偶校验），从而使码距变为2。  
常见的有：`水平奇偶校验码`，`垂直奇偶校验码`，`水平垂直校验码`
2. 海明码
海明码利用奇偶性来检错和纠错。在数据位之间的特定位置上插入K个校验位，通过扩大码距来实现检错和纠错。
3. 循环冗余校验码
利用多项式为K个数据位产生R个校验位，编码长度K+R记为N，N为CRC码的字长，又称为(n,k)码。   -->