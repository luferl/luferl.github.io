---
title: 系统架构设计师教程(施工中)
date: 2020-12-24 10:08:59
categories: 读书笔记
tags: [读书笔记]
---
# 第一章 计算机组成与体系结构
## 1.1 计算机系统组成
###  1.1.1 计算机硬件的组成  
&emsp;&emsp;计算机系统由`运算器`，`控制器`，`存储器`，`输入设备`，`输出设备`五部分组成。

1. 控制器  
&emsp;&emsp;控制器是分析和执行指令的部件，也是统一指挥并控制计算机各部件协调工作的中心部件，所依据的是机器指令。  
&emsp;&emsp;控制器的组成包含：
    * 程序计数器`PC`：存储P下一条要执行指令的地址。
    * 指令寄存器`IR`：存储即将执行的指令。
    * 指令译码器`ID`：对指令中的操作码字段进行分析解释。
    * 时序部件：提供时序控制信号。
2. 运算器  
&emsp;&emsp;运算器也称为算术逻辑单元（ArithmeticandLogicUnit，ALU），其主要功能是在控制器的控制下完成各种算术运算和逻辑运算。   
&emsp;&emsp;运算器的组成包含：  
    * 算术逻辑单元`ALU`：数据的算术运算和逻辑运算。
    * 累加寄存器`AC`：通用寄存器，为ALU提供一个工作区，用于暂存数据。
    * 数据缓冲寄存器`DR`：写内存时，暂存指令或数据。
    * 状态条件寄存器`PSW`：存状态标志与控制标志（争议点：也有将其归为控制器的）。  
3. 主存储器  
&emsp;&emsp;主存储器也称为内存储器（通常简称为“内存”或“主存”）。存储现场操作的信息与中间结果，包括机器指令和数据。  
4. 辅助存储器  
&emsp;&emsp;辅助存储器也称为外存储器，通常简称为外存或辅存。存储需要长期保存的各种信息。  
5. 输入设备  
&emsp;&emsp;输入设备的任务是把人们编好的程序和原始数据送到计算机中去,并且将它们转换成计算机内部所能识别和接受的信息方式。按输入信息的形态可分为字符（包括汉字）输入、图形输入、图像输入及语音输入等。目前，常见的输入设备有键盘、鼠标、扫描仪等。  
6. 输出设备  
&emsp;&emsp;输出设备的任务是将计算机的处理结果以人或其他设备所能接受的 形式送出计算机。目前，最常用的输出设备是打印机和显示器。有些设备既可以是输入设备，同时也可以是输出设备，例如，辅助存储器、自动控制和检测系统中使用的数模转换装置等。

### 1.1.2 计算机系统结构的分类
#### 1.存储程序的概念
&emsp;&emsp;“存储程序”由冯·诺依曼提出，是计算机的系统架构，符合存储程序概念的计算机统称为冯·诺依曼型计算机。它的基本含义有以下三点：    
* 计算机由运算器、存储器、控制器、输入设备、输出设备5部分组成。
* 计算机内部由二进制来表示指令和数据。
* 将编好的程序和数据事先存入存储器中，然后再启动计算机工作。

#### 2. Flynn分类
&emsp;&emsp;1966年，Michael.J.Flynn提出根据`指令流`、`数据流`的多倍性特征对计算机系统进行分类（通常称为 Flynn 分类法）。  

* 指令流：指机器执行的指令序列
* 数据流：指由指令流调用的数据序列，包括输入数据和中间结果，但不包括输出数据。  

&emsp;&emsp;Flynn根据不同的指令流-数据流组织方式，把计算机系统分成以下四类：

1. 单指令流单数据流（Single Instruction stream and Single Data stream，`SISD`）  
&emsp;&emsp;SISD其实就是传统的顺序执行的单处理器计算机，其指令部件每次只对一条指令进行译码，并只对一个操作部件分配数据。  
2. 单指令流多数据流（Single Instruction stream and Multiple Data stream，`SIMD`）  
&emsp;&emsp;SIMD以并行处理机（矩阵处理机）为代表，并行处理机包括多个重复的处理单元，由单一指令部件控制，按照同一指令流的要求为它们分配各自所需的不同数据。  
3. 多指令流单数据流（Multiple Instruction stream and Single Data stream，`MISD`）  
&emsp;&emsp;MISD具有多个处理单元，按多条不同指令的要求对同一数据流及其中间结果进行不同的处理。一个处理单元的输出又作为另一个处理单元的输入。这类系统实际上很少见到。有文献把流水线看作多个指令部件，称流水线计算机是 MISD。
4. 多指令流多数据流（Multiple Instruction stream and Multiple Data stream，`MIMD`）  
&emsp;&emsp;MIMD是指能实现作业、任务、指令等各级全面并行的多机系统。如多核处理器、多处理机等。

### 1.1.3 复杂指令集系统与精简指令集系统
&emsp;&emsp;一个处理器支持的指令和指令的字节级编码成为其指令集体系结构，有CISC和RISC两种发展途径。

#### 1. CISC
&emsp;&emsp;CISC(Complex Instruction Set Computer)全称是复杂指令系统计算机，它的基本思想是进一步增强其原有指令的功能，用更为复杂的新指令取代原先由软件子程序完成的功能。`目前使用的绝大多数计算机都属于CISC类型`。  

&emsp;&emsp;CSIC的特点如下：

1. 指令数量众多  
&emsp;&emsp;指令系统拥有大量的指令，通常有 100～250 条。  
2. 指令使用频率相差悬殊  
&emsp;&emsp;最常使用的是一些比较简单的指令，仅占指令总数的20%，但在程序中出现的频率却占80%。而大部分复杂指令却很少使用。  
3. 支持多种寻址方式  
&emsp;&emsp;支持的寻址方式通常为 5～20 种。  
4. 变长的指令  
&emsp;&emsp;指令长度不是固定的，变长的指令增加指令译码电路的复杂性。  
5. 指令可以对主存单元中的数据直接进行处理  
&emsp;&emsp;典型的 CISC 通常都有指令能够直接对主存单元中的数据进行处理，`但其执行速度较慢`。  
6. 以微程序控制为主  
&emsp;&emsp;CISC的指令系统很复杂，难以用硬布线逻辑（组合逻辑）电路实现控制器，通常采用微程序控制。

#### 2. RISC
&emsp;&emsp;RISC(Reduced Instruction Set Computer)全称是精简指令系统计算机。它的基本思想是通过减少指令总数和简化指令功能降低硬件设计的复杂度，使指令能单周期运行，并通过优化编译提高指令的执行速度，采用硬布线逻辑优化编译程序。

&emsp;&emsp;RISC的特点如下：

1. 指令数量少  
&emsp;&emsp;优先选取使用频率最高的一些简单指令和一些常用指令，避免使用复杂指令。只提供了LOAD（从存储器中读数）和STORE（把数据写入存储器）两条指令对存储器操作，其余所有的操作都在 CPU 的寄存器之间进行。  
2. 指令的寻址方式少  
&emsp;&emsp;通常只支持寄存器寻址方式、立即数寻址方式和相对寻址方式。  
3. 指令长度固定，指令格式种类少  
&emsp;&emsp;因为 RISC 指令数量少、格式少、相对简单，其指令长度固定，指令之间各字段的划分比较一致，译码相对容易。  
4. 以硬布线逻辑控制为主  
&emsp;&emsp;为了提高操作的执行速度，通常采用硬布线逻辑（组合逻辑）来构建控制器。  
5. 单周期指令执行  
&emsp;&emsp;因为简化了指令系统，很容易利用流水线技术，使得大部分指令都能在一个机器周期内完成。少数指令可能会需要多周期，例如LOAD/STORE 指令因为需要访问存储器，其执行时间就会长一些。  
6. 优化的编译器  
&emsp;&emsp;RISC的精简指令集使编译工作简单化。因为指令长度固定、格式少、寻址方式少，编译时不必在具有相似功能的许多指令中进行选择，也不必为寻址方式的选择而费心，同时易于实现优化，从而可以生成高效率执行的机器代码。
7. CPU中的通用寄存器数量多  
&emsp;&emsp;一般在32个以上，有的可达上千个。

### 1.1.4 总线

&emsp;&emsp;总线是一组能为多个部件分时共享的公共信息传送线路。共享是指总线上可以挂接多个部件，各个部件之间相互交换的信息都可以通过这组公共线路传送；分时是指同一时刻只允许有一个部件向总线发送信息，如果出现两个或两个以上部件同时向总线发送信息，势必导致信号冲突。当然，在同一时刻，允许多个部件同时从总线上接收相同的信息。  
&emsp;&emsp;按总线相对于 CPU 或其他芯片的位置可分为`内部总线`和`外部总线`两种。在 CPU 内部，寄存器之间和算术逻辑部件ALU与控制部件之间传输数据所用的总线称为内部总线；外部总线是指CPU与内存RAM、ROM和输入/输出设备接口之间进行通信的通路。由于CPU通过总线实现程序取指令、内存/外设的数据交换，在 CPU 与外设一定的情况下，`总线速度是制约计算机整体性能的最大因素`。  
&emsp;&emsp;按总线功能来划分，又可分为`地址总线`、`数据总线`、`控制总线`三类，人们通常所说的总线都包括这三个组成部分，地址总线用来传送地址信息，数据总线用来传送数据信息，控制总线用来传送各种控制信号。

## 1.2 存储器系统
 
&emsp;&emsp;传统的存储器系统一般分为`高速缓冲存储器（Cache）`、`主存`、`辅存`三级。主存可由CPU直接访问，存取速度快，但容量较小，一般用来存放当前正在执行的程序和数据。辅存设置在主机外部，它的存储容量大，价格较低，但存取速度较慢，一般用来存放暂时不参与运行的程序和数据，CPU 不可以直接访问辅存，辅存中的程序和数据在需要时才传送到主存，因此它是主存的补充和后援。当 CPU 速度很高时，为了使访问存储器的速度能与 CPU 的速度相匹配，又在主存和 CPU 间增设了一级 Cache。Cache 的存取速度比主存更快，但容量更小，用来存放当前最急需处理的程序和数据，以便快速地向 CPU 提供指令和数据。因此，计算机采用多级存储器体系，确保能够获得尽可能高的存取速率，同时保持较低的成本。  
&emsp;&emsp;存储器中数据常用的存取方式有`顺序存取`、`直接存取`、`随机存取`和`相联存取`四种。
1. 顺序存取  
&emsp;&emsp;存储器的数据以记录的形式进行组织。对数据的访问必须按特定的线性顺序进行。磁带存储器采用顺序存取的方式。
2. 直接存取  
&emsp;&emsp;与顺序存取相似，直接存取也使用一个共享的读写装置对所有的数据进行访问。但是，每个数据块都拥有唯一的地址标识，读写装置可以直接移动到目的数据块所在位置进行访问。存取时间也是可变的。磁盘存储器采用直接存取的方式。
3. 随机存取  
&emsp;&emsp;存储器的每一个可寻址单元都具有自己唯一的地址和读写装置，系统可以在相同的时间内对任意一个存储单元的数据进行访问，而与先前的访问序列无关。主存储器采用随机存取的方式。
4. 相联存取  
&emsp;&emsp;相联存取也是一种随机存取的形式，但是选择某一单元进行读写是取决于其内容而不是其地址。与普通的随机存取方式一样，每个单元都有自己的读写装置，读写时间也是一个常数。使用相联存取方式，可以对所有的存储单元的特定位进行比较，选择符合条件的单元进行访问。为了提高地址映射的速度，Cache 采取相联存取的方式。
    
### 1.2.1 主存储器
&emsp;&emsp;主存用来存放计算机运行期间所需要的程序和数据，CPU可直接随机地进行读/写。主存具有一定容量，存取速度较高。由于CPU要频繁地访问主存，所以主存的性能在很大程度上影响了整个计算机系统的性能。根据工艺和技术不同，主存可分为`随机存取存储器`和`只读存储器`。

#### 1.随机存取存储器
&emsp;&emsp;随机存取存储器（Random Access Memory，RAM）既可以写入也可以读出，但断电后信息无法保存，因此只能用于暂存数据。RAM又可分为DRAM（Dynamic RAM，动态RAM）和SRAM（Static RAM，静态RAM）两种，DRAM 的信息会随时间逐渐消失，因此需要定时对其进行刷新维持信息不丢失；SRAM 在不断电的情况下信息能够一直保持而不会丢失。DRAM 的密度大于 SRAM 且更加便宜，但 SRAM 速度快，电路简单（不需要刷新电路），然而容量小，价格高。
#### 2.只读存储器
&emsp;&emsp;只读存储器（Read Only Memory，ROM）可以看作 RAM 的一种特殊形式，其特点是存储器的内容只能随机读出而不能写入。这类存储器常用来存放那些不需要改变的信息。由于信息一旦写入存储器就固定不变了，即使断电，写入的内容也不会丢失，所以又称为固定存储器。ROM 一般用于存放系统程序 BIOS（Basic Input Output System，基本输入输出系统）。
#### 3.内存编址方法
&emsp;&emsp;在计算机系统中，存储器中每个单元的位数是相同且固定的，称为存储器编址单位。不同的计算机，存储器编址的方式不同，主要有字编址和字节编址。  
&emsp;&emsp;内存一般以字节（8 位）为单位，或者以字为单位（字的长度可大可小，例如 16 位或者 32 位等，在这类试题中，一般会给出字的大小）。
```Example
例如，内存地址从 AC000H 到 C7FFFH
则共有C7FFFFH-AC000H+1=1C000H 个地址单元

转换为10进制则有 
 12*16^3+1*16^4
=12*2^12+1*2^16
=12*2^2KB+1*2^6KB
=112KB

如果该内存地址按字（16bit）编址，则共有 112KB*16 位。
假设该内存由 28 片存储器芯片构成，已知构成此内存的芯片每片有 16KB 个存储单元，则该芯片每个存储单元存储
（112KB*16）/（28*16KB）=4 位。
```

### 1.2.2 辅助存储器
#### 1．磁带存储器
&emsp;&emsp;磁带存储器是一种顺序存取的设备，其特点包括：存取时间较长，但存储容量大，便于携带，价格便宜。磁带应用的场景越来越少，目前主要用于资料的归档保存。
#### 2．硬盘存储器
&emsp;&emsp;在硬盘中，信息分布呈以下层次：`记录面`、`圆柱面`、`磁道`和`扇区`，如图所示。 

[![硬盘信息分布示意图](https://s3.ax1x.com/2020/12/24/rg5IJJ.png)](https://imgchr.com/i/rg5IJJ)

&emsp;&emsp;一台硬盘驱动器中有多个磁盘片，每个盘片有两个记录面，每个记录面对应一个磁头，所以`记录面号就是磁头号`，如图中（a）所示。    
&emsp;&emsp;所有的磁头安装在一个公用的传动设备或支架上，磁头一致地沿盘面径向移动，`单个磁头不能单独地移动`。在记录面上，一条条磁道形成一组同心圆，最外圈的磁道为 0 号，往内则磁道号逐步增加，如图中（b）所示。通常将一条磁道划分为若干个段，每个段称为一个扇区或扇段，每个扇区存放一个定长信息块（例如，512 个字节）。一条磁道划分多少扇区，每个扇区可存放多少字节，一般由操作系统决定。磁道上的扇区编号从 1 开始，不像磁头或柱面编号从 0开始。    
&emsp;&emsp;在一个盘组中，各记录面上相同编号（位置）的各磁道构成一个柱面，如图中（c）所示。若每个磁盘片有 m 个磁道，则该硬盘共有 m 个柱面。引入柱面的概念是为了提高硬盘的存储速度。当主机要存入一个较大的文件时，若一条磁道存不完，就需要存放在几条磁道上。这时，应首先将一个文件尽可能地存放在同一柱面中。如果仍存放不完，再存入相邻的柱面内。  
&emsp;&emsp;在磁盘上进行信息的读写时，首先需要定位到目标磁道，这个过程称之为`寻道`，寻道所消耗的时间称为`寻道时间`。定位到目标磁道后，需要定位到目标扇区，此过程通过旋转盘片完成，平均旋转`半圈`可到目标位置。故磁盘访问时间为：`磁盘访问时间（存取时间） = 寻道时间+旋转延迟时间`

### 1.2.3 Cache存储器
&emsp;&emsp;Cache 通常采用相联存储器（ContentAddressable Memory，CAM）。CAM 是一种基于数据内容进行访问的存储设备。当对其写入数据时，CAM 能够自动选择一个未用的空单元进行存储；当要读出数据时，不是给出其存储单元的地址，而是直接给出该数据或者该数据的一部分内容，CAM 对所有存储单元中的数据同时进行比较，并标记符合条件的所有数据以供读取。由于比较是同时、并行进行的，所以，这种基于数据内容进行读写的机制，其速度比基于地址进行读写的方式要快很多。
#### 1．Cache基本原理
&emsp;&emsp;使用 Cache 改善系统性能的依据是程序的`局部性原理`。  
&emsp;&emsp;局部性原理是指程序在执行时呈现出局部性规律，即在一较短的时间内，程序的执行仅局限于某个部分。相应地，它所访问的存储空间也仅局限于某个区域。  
&emsp;&emsp;根据程序的局部性原理，可以把目前常用或将要用到的信息预先放在 Cache 中。当CPU 需要读取数据时，首先在 Cache 中查找是否有所需内容，如果有，则直接从 Cache 中读取；若没有，再从内存中读取该数据，然后同时送往 CPU 和 Cache。如果 CPU 需要访问的内容大多都能在 Cache 中找到（称为`访问命中`），则可以大大提高系统性能。  
&emsp;&emsp;如果以 h 代表对 Cache 的访问命中率（“1-h”称为失效率，或者称为未命中率），t1 表示 cache 的周期时间，t2 表示内存的周期时间，以读操作为例，使用“Cache+主存储器”的系统的平均周期为 t3。则：

$$t3=t1*h+t2*(1-h)$$

&emsp;&emsp;系统的平均存储周期与命中率有很密切的关系，命中率的提高即使很小也能导致性能上的较大改善。

```Example
设某计算机主存的读/写时间为 l00ns，有一个指令和数据合一的Cache
已知该Cache的读/写时间为 10ns，取指令的命中率为 98%，取数的命中率为 95%
在执行某类程序时，约有 1/5 指令需要存/取一个操作数。
假设指令流水线在任何时候都不阻塞，则设置 Cache 后，每条指令的平均访存时间约为：
(2%*100ns+98%*10ns)+1/5*(5%*100ns+95%*10ns)=14.7ns
```

#### 2. 映射机制
&emsp;&emsp;当 CPU 发出访存请求后，存储器地址先被送到 Cache 控制器以确定所需数据是否已在 Cache 中，若命中则直接对 Cache 进行访问。这个过程称为 Cache 的地址映射（映像）。  
&emsp;&emsp;在 Cache 的地址映射中，主存和 Cache 将均分成容量相同的块（页）。常见的映射方法有`直接映射`、`全相联映射`和`组相联映射`。

* 直接映射  

&emsp;&emsp;直接映射以随机存取存储器作为 Cache 存储器，硬件电路较简单。在进行映射时，主存地址被分成三个部分，从高到低依次为：区号、页号以及页内地址，如图所示。  

[![直接映射方式的主存地址](https://s3.ax1x.com/2020/12/24/rgq5Bn.png)](https://imgchr.com/i/rgq5Bn)

&emsp;&emsp;在本例中，内存容量为 1GB，Cache 容量为 8MB，页面的大小为 512KB。直接映射中先分区，再分页。一个区的大小就是 Cache 容量的大小，所以一共分：1GB/8MB=128 个区，区号7位。每个区分：8MB/512KB=16个页，所以页号为 4 位。  
&emsp;&emsp;在直接映射方式中，每个主存页只能复制到某一固定的 Cache 页中，如下图所示。直接映射方式的映射规律是：主存中每个区的第 0 页，只能进入到 Cache 的第 0 页。即：若当前时刻 Cache 中 0 号页已被占据，而 1-15 号页空闲，现在要将 1 区第 0 页（即内存的 16 页）调入 Cache 是会发生冲突的。所以直接映射的块冲突率非常高。

[![直接映射方式](https://s3.ax1x.com/2020/12/24/rgLwCT.png)](https://imgchr.com/i/rgLwCT)

&emsp;&emsp;由于每个区的 N 号页，都必须进入到 Cache 的 N 号页，所以只需要记录区号即可。

* 全相联映射

&emsp;&emsp;全相联映射使用相联存储器组成Cache存储器。在全相联映射方式中，主存的每一页可以映射到Cache的任一页。如果淘汰Cache中某一页的内容，则可调入任一主存页的内容，因而较直接映射方式灵活。  
&emsp;&emsp;在全相联映射方式中，主存地址分为两个部分，分别为地址部分（主存页标记）和数据部分（页内地址）。数据部分用于存放数据，而地址部分则存放该数据的存储器地址。如图所示。

[![主存储示例](https://s3.ax1x.com/2020/12/24/rgjuU1.png)](https://imgchr.com/i/rgjuU1)

&emsp;&emsp;当进行映射时，在我们给定的例子中，当程序访存时，则高 11 位给出主存页号，低19 位给出页内地址。因为每个 Cache 页可映射到 2048 个主存页中的任一页，所以每页的Cache 标记也需要 11 位，以表明它现在所映射的主存页号。因此，Cache 标记信息位数增加，比较逻辑成本随之增加。  
&emsp;&emsp;在全相联映射方式中，主存地址不能直接提取 Cache 页号，而是需要将主存页标记与Cache 各页的标记逐个比较，直到找到标记符合的页（访问 Cache 命中），或者全部比较完后仍无符合的标记（访问 Cache 失败）。因此`这种映射方式速度很慢，失掉了高速缓存的作用，这是全相联映射方式的最大缺点`。如果让主存页标记与各 Cache 标记同时比较，则成本又太高。全相联映射方式因比较器电路难于设计和实现，只适用于小容量 Cache。  

* 组相联映射

&emsp;&emsp;组相联映射（页组映射）介于直接映射和全相联映射之间，是这两种映射的一种折衷方案。全相联映射方式以页为单位，可自由映射，没有固定的对应关系。直接映射方式中，主存分组，主存组内的各页与 Cache 的页之间采取的是固定的映射关系，但各组均可映射到Cache 中。在组相联映射方式中，主存与 Cache 都分组，主存中一个组内的页数与 Cache 的分组数相同，如图所示。

[![组相连映射方式](https://s3.ax1x.com/2020/12/24/rgjLI1.png)](https://imgchr.com/i/rgjLI1)

&emsp;&emsp;在上图给出的例子中，主存分 128 个区，每个区 8 个组，每个组 2 个页。组相联映射方式的主存地址组织如下图所示。

[![组相联映射主存地址示例](https://s3.ax1x.com/2020/12/24/rgvGWV.png)](https://imgchr.com/i/rgvGWV)

&emsp;&emsp;组相联映射的规则是：主存中的组与 Cache 的组形成直接映射关系，而每个组内的页是全相联映射关系。如主存 1 区 0 页，他在 0 组中，所以只能进入 Cache 的 0 组中，至于进入到 Cache 的 0 组 0 页，还是 0 组 1 页，并无强制要求，可任意放置。  
&emsp;&emsp;在组相联映射中，Cache 中每一页的标记位长度为 8 位，因为此时除了要记录区号，还得记录组号，即区号 7 位加组号 1 位等于 8 位。  
&emsp;&emsp;在组相联映射中，由于 Cache 中每组有若干可供选择的页，因而它在映射定位方面较直接映射方式灵活；每组页数有限，因此付出的代价不是很大，可以根据设计目标选择组内页数。

#### 3. 替换算法

&emsp;&emsp;当 Cache 产生了一次访问未命中之后，相应的数据应同时读入 CPU 和 Cache。但是当Cache 已存满数据后，新数据必须替换（淘汰）Cache 中的某些旧数据。最常用的替换算法有以下三种：
1. 随机算法  
&emsp;&emsp;这是最简单的替换算法。随机法完全不管 Cache 块过去、现在及将来的使用情况，简单地根据一个随机数，选择一块替换掉。  
2. 先进先出（First In and First Out，FIFO）算法    
&emsp;&emsp;按调入 Cache 的先后决定淘汰的顺序，即在需要更新时，将最先进入 Cache 的块作为被替换的块。这种方法要求为每块做一记录，记下它们进入 Cache 的先后次序。这种方法容易实现，而且系统开销小。其缺点是`可能会把一些需要经常使用的程序块（如循环程序）替换掉`。  
3. 近期最少使用（Least Recently Used，LRU）算法   
&emsp;&emsp;LRU 算法是把 CPU 近期最少使用的块作为被替换的块。这种替换方法需要随时记录 Cache 中各块的使用情况，以便确定哪个块是近期最少使用的块。LRU 算法相对合理，但实现起来比较复杂，系统开销较大。通常需要对每一块设置一个称为“年龄计数器”的硬件或软件计数器，用以记录其被使用的情况。  

#### 4．写操作
&emsp;&emsp;因为需要保证缓存在 Cache 中的数据与内存中的内容一致，相对读操作而言，Cache 的写操作比较复杂，常用的有以下几种方法。  
1. 写直达（write through）  
&emsp;&emsp;当要写 Cache 时，数据同时写回内存，有时也称为写通。当某一块需要替换时，也不必把这一块写回到主存中去，新调入的块可以立即把这一块覆盖掉。这种方法实现简单，而且能随时保持主存数据的正确性，但`可能增加多次不必要的主存写入`，会降低存取速度。  
2. 写回（write back）  
&emsp;&emsp;CPU 修改 Cache 的某一块后，相应的数据并不立即写入内存单元，而是当该块从 Cache 中被淘汰时，才把数据写回到内存中。在采用这种更新策略的Cache块表中，一般有一个标志位，当一块中的任何一个单元被修改时，标志位被置“1”。    
&emsp;&emsp;在需要替换掉这一块时，如果标志位为“1”，则必须先把这一块写回到主存中去之后，才能再调入新的块；如果标志位为“0”，则这一块不必写回主存，只要用新调入的块覆盖掉这一块即可。这种方法的优点是`操作速度快`，缺点是`因主存中的字块未随时修改而有可能出错`。  
3. 标记法  
&emsp;&emsp;对 Cache 中的每一个数据设置一个有效位。当数据进入 Cache 后，有效位置“1”；而当 CPU 要对该数据进行修改时，数据只需写入内存并同时将该有效位置“0”。当要从 Cache 中读取数据时需要测试其有效位，若为“l”则直接从 Cache 中取数，否则，从内存中取数。  

## 1.3 流水线
&emsp;&emsp;流水线技术把一个任务分解为若干顺序执行的子任务，不同的子任务由不同的执行机构负责执行，而这些机构可以`同时并行工作`。在任一时刻，任一任务只占用其中一个执行机构，这样就可以实现多个任务的重叠执行，以提高工作效率。  
### 1.3.1 流水线周期
&emsp;&emsp;流水线应用过程中，会将需要处理的工作分为 N 个阶段，`最耗时的那一段所消耗的时间为流水线周期`。如：使用流水线技术执行 100 条指令，每条指令取指 2ms，分析 4ms，执行 1ms，则流水线周期为 4ms。  
### 1.3.2 计算流水线执行时间
&emsp;&emsp;延续上面的场景，将 1 个任务的执行过程可分成 N 个阶段，假设每个阶段完成时间为 t，则完成该任务所需的时间即为 Nt。若以传统的方式，则完成 k 个任务所需的时间是kNt；而使用流水线技术执行，且花费的时间是 Nt+(k-1)t。也就是说，除了第 1 个任务需要完整的时间外，其他都通过并行，节省下了大量的时间。所以流水线的执行时间可通俗的表达为：  
>流水线执行时间=第 1 条指令的执行时间+（n-1）\*流水线周期   
注：n 代表需要处理的任务数量。

```
    在考试时，又需要特别注意一个细节问题。
    流水线的执行时间计算，其实进一步可以分理论情况与实践情况两种不同的处理方式。
例：
    某计算机系统，一条指令的执行需要经历取指（2ms）、分析（4ms）、执行（1ms）三个阶段，现要执行 100 条指令，利用流水线技术需要多长时间?
    理论上来说，1 条指令的执行时间为：2ms+4ms+1ms=7ms。
    所以：理论流水线执行时间=2ms+4ms+1ms+(100-1)*4=403ms。
    而实际上，真正做流水线处理时，考虑到处理的复杂性，会将指令的每个执行阶段的时间都统一为流水线周期，即 1 条指令的执行时间为：4ms+4ms+4ms=12ms。 
    所以：实际流水线执行时间=4ms+4ms+4ms+(100-1)*4=408ms。

    考试时 80%以上的概率采用理论公式计算，所以考试时需要以理论公式计算，若计算的结果无正确选项才考虑采用实际公式计算。
```
### 1.3.3 流水线的吞吐率
&emsp;&emsp;流水线的吞吐率（Though Put rate，TP）是指在`单位时间`内`流水线所完成的任务数量或输出的结果数量`。有些文献也称为平均吞吐率、实际吞吐率。  
&emsp;&emsp;计算流水线吞吐率的最基本的公式如下：

$$ 
TP=\frac {n} {T_k} 
$$

&emsp;&emsp;其中n为任务数量，$T_k$是处理完成n个任务所用的时间  

&emsp;&emsp;流水线的最大吞吐率为：

$$TP_{max}=\lim_{n \to \infty} \frac n {(k+n-1)\Delta t}=\frac 1 {\Delta t} $$

### 1.3.4 流水线的加速比
&emsp;&emsp;在流水线中，因为在同一时刻，有多个任务在重叠地执行，虽然完成一个任务的时间与单独执行该任务相近（甚至由于分段的缘故，可能更多一些），但是从整体上看完成多个任务所需的时间则大大减少。   
&emsp;&emsp;完成同样一批任务，`不使用流水线所用的时间`与`使用流水线所用的时间`之比称为流水线的加速比（speedup ratio）。如果不使用流水线，即顺序执行所用的时间为 T0 ，使用流水线的执行时间为 Tk ，则计算流水线加速比的基本公式如下：

$$ S=\frac {T_0} {T_k} $$

&emsp;&emsp;如果流水线各个流水段的执行时间都相等（设为Δt），则一条 k 段流水线完成 n 个连续任务所需要的时间为(k+n-1)Δt。如果不使用流水线，即顺序执行这 n 个任务，则所需要的时间为 nkΔt。  
&emsp;&emsp;因此，各个流水段执行时间均相等的一条 k 段流水线完成 n 个连续任务时的实际加速比为：

$$ S=\frac {nk\Delta t} {(k+n-1)\Delta t}=\frac {nk} {k+n-1}$$

&emsp;&emsp;这种情况下的最大加速比为：

$$ S_{max}=\lim_{n \to \infty} \frac {nk} {k+n-1}=k$$

# 第二章 操作系统
## 2.1 操作系统的类型与结构
### 2.1.1 操作系统的定义
&emsp;&emsp;操作系统（Operating System，OS）是计算机系统中的核心系统软件，负责管理和控制计算机系统中的硬件和软件资源，合理地组织计算机工作流程和有效地利用资源，在计算机与用户之间起接口的作用。

### 2.1.2 操作系统的分类
&emsp;&emsp;按照操作系统的功能划分，操作系统的基本类型主要有
* 批处理操作系统
* 分时操作系统
* 实时操作系统
* 网络操作系统
* 分布式操作系统
* 嵌入式操作系统
* 微内核操作系统

## 2.2 操作系统基本原理
### 2.2.1 进程管理
#### 1. 进程的概念
&emsp;&emsp;在多道程序处理系统中有多个并发执行的程序，为了描述系统中程序执行时动态变化的过程引入了`进程`。进程是资源分配和独立运行的基本单位。
#### 2．进程的状态转换
&emsp;&emsp;由进程运行的间断性，决定了进程至少具有以下三种状态：
1. 就绪状态  
&emsp;&emsp;当进程已分配了除 CPU 以外的所有必要的资源后，只要能再获得处理机，便能立即执行，把这时的进程状态称为`就绪状态`。在一个系统中，可以有多个进程同时处于就绪状态，通常把它们排成一个队列，称为`就绪队列`。
2. 执行状态  
&emsp;&emsp;指进程已获得处理机，其程序正在执行。在单处理机系统中，只能有一个进程处于执行状态。
3. 阻塞状态  
&emsp;&emsp;指进程因发生某事件（如请求 I/O、申请缓冲空间等）而暂停执行时的状态，亦即进程的执行受到阻塞，故称这种暂停状态为`阻塞状态`，有时也称为`等待`状态或`睡眠`状态。通常将处于阻塞状态的进程排成一个队列，称为`阻塞队列`。

&emsp;&emsp;进程的状态随着自身的推进和外界的变化而变化。例如，就绪状态的进程被进程调度程序选中进入执行状态；执行状态的进程因等待某一事件的发生转入等待状态；等待状态的进程所等待事件来到便进入就绪状态。进程的状态可以动态地相互转换，但阻塞状态的进程不能直接进入执行状态，就绪状态的进程不能直接进入阻塞状态。在任何时刻，任何进程都处于且只能处于这其中一种状态。进程状态的变化情况如下：
1. 运行态→等待态  
&emsp;&emsp;一个进程运行中启动了外围设备，它就变成等待外围设备传输信息的状态。  
&emsp;&emsp;进程在运行中申请资源（主存储空间及外围设备因得不到满足）时，变成等待资源状态。  
&emsp;&emsp;进程在运行中出现了故障（程序出错或主存储器读写错误等），变成等待干预状态。  
2. 等待态→就绪态  
&emsp;&emsp;外围设备工作结束后等待外围设备传输信息的进程结束等待。  
&emsp;&emsp;等待的资源能得到满足时（另一个进程归还了资源），则等待资源者就结束等待。  
&emsp;&emsp;故障排队后让等待干预的进程结束等待。  
&emsp;&emsp;任何一个结束等待的进程必须先变成就绪状态，待分配到处理器后才能运行。  
3. 运行态→就绪态  
&emsp;&emsp;进程用完了一个使用处理器的时间后强迫该进程暂时让出处理器。  
&emsp;&emsp;当有更优先权的进程要运行时也迫使正在运行的进程让出处理器。     
&emsp;&emsp;由于自身或外界原因成为等待状态的进程让出处理器时，它的状态就变成就绪状态。  
4. 就绪态→运行态  
&emsp;&emsp;等待分配处理器的进程，系统按一种选定的策略从处于就绪状态的进程中选择一个进程，让它占用处理器，那个被选中的进程就变成了运行态。

&emsp;&emsp;可用状态转换图表示如下：
[![进程状态转换图](https://s3.ax1x.com/2020/12/28/roqSZ8.png)](https://imgchr.com/i/roqSZ8)


#### 3．挂起状态
&emsp;&emsp;在一些系统中，增加了一些新的进程状态，其中最重要的是挂起状态。引入挂起状态的原因有：
1. 对换的需要  
&emsp;&emsp;为了缓和内存紧张的情况，而将内存中处于阻塞状态的进程换至外存上，使进程又处于一种有别于阻塞状态的新状态。因为即使该进程所期待的事件发生，该进程仍不具备执行条件而不能进入就绪队列，称这种状态为挂起状态。
2. 终端用户的请求  
&emsp;&emsp;当终端用户在自己的程序运行期间，发现有可疑问题时，往往希望使自己的进程暂停下来。也就是说，使正在执行的进程暂停执行，若是就绪进程，则不接受调度以便研究其执行情况或对程序进行修改。把这种静止状态也称为挂起状态。  
3. 父进程请求  
&emsp;&emsp;父进程常希望挂起自己的子进程，以便考查和修改子进程，或者协调各子进程间的活动。
4. 负荷调节的需要  
&emsp;&emsp;当实时系统中的工作负荷较重，有可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统正常运行。
5. 操作系统的需要  
&emsp;&emsp;操作系统希望挂起某些进程，以便检查运行中资源的使用情况及进行记账。

&emsp;&emsp;综上所述，不难了解挂起状态具有以下三个属性。  
1. 被挂起的进程，原来可能处于就绪状态，此时进程（被挂起）的状态称为挂起就绪；若被挂起的进程原来处于阻塞状态，此时的状态称为挂起阻塞。不论哪种状态，该进程都是不可能被调度而执行的。
2. 处于挂起阻塞状态的进程，其阻塞条件与挂起条件无关；当进程所期待的事件出现后，进程虽不再被阻塞，但仍不能运行，这时，应将该进程从`静止阻塞`状态转换为`挂起就绪`状态。
3. 进程可以由其自身挂起，也可由用户或操作系统等将之挂起。其目的都在于阻止进程继续运行，被挂起的进程只能用显式方式来激活，以便从挂起状态中解脱出来。

&emsp;&emsp;下图所示为具有挂起操作的进程状态的演变情况：

[![带有挂起操作的进程状态演变图](https://s3.ax1x.com/2020/12/28/roL4AO.png)](https://imgchr.com/i/roL4AO)

#### 4．进程互斥与同步
&emsp;&emsp;进程互斥：一组并发进程中一个或多个程序段，因共享某一共有资源而导致必须以一个不允许交叉执行的单位执行。也就是说互斥是要保证临界资源在某一时刻只被一个进程访问。`（竞争关系）`  
&emsp;&emsp;进程同步：把异步环境下的一组并发进程因直接制约而互相发送消息而进行互相合作、互相等待，使得各进程按一定的速度执行的过程称为进程同步。也就是说进程之间是异步执行的，同步即是使各进程按一定的制约顺序和速度执行。`（协作关系）`

&emsp;&emsp;进程在并发执行中可以共享系统中的资源。但是临界资源的访问则必须互斥进行，必须有专门的同步机构来协调它们，协调准则如下：
1. 空闲让进  
&emsp;&emsp;无进程处于临界区时，若有进程要求进入临界区则立即允许其进入。
2. 忙则等待  
&emsp;&emsp;当已有进程进入其临界区时，其他试图进入各自临界区的进程必须等待，以保证诸进程互斥地进入临界区。
3. 有限等待  
&emsp;&emsp;有若干进程要求进入临界区时，应在有限时间内使一进程进入临界区，即它们不应相互等待而谁也不进入临界区。
4. 让权等待  
&emsp;&emsp;对于等待进入临界区的进程必须释放其占有的 CPU。

&emsp;&emsp;信号量可以有效地实现进程的同步和互斥。在操作系统中，信号量是一个整数。当信号量大于等于 0 时，代表可供并发进程使用的资源实体数，当信号量小于零时则表示正在等待使用临界区的进程数。建立一个信号量必须说明所建信号量代表的意义和设置初值，以及建立相应的数据结构，以便指向那些等待使用该临界区的进程。  
&emsp;&emsp;对信号量只能施加特殊的操作：P 操作和 V 操作。P 操作和 V 操作都是不可分割的原子操作，也称为原语。因此，P 原语和 V 原语执行期间不允许中断发生。  
&emsp;&emsp;P（sem）操作的过程是将信号量 sem 值减 l，若 sem 的值成负数，则调用 P 操作的进程暂停执行，直到另一个进程对同一信号量做 V 操作。V（sem）操作的过程是将信号量sem 值加 1，若 sem 的值小于等于 0，则从相应队列（与 sem 有关的队列）中选一个进程并唤醒它。

&emsp;&emsp;一般 P 操作与 V 操作的定义如下所述。
```
P 操作：
P（sem）{
    sem = sem - 1;
    if（sem < 0）
        进程进入等待状态；
    else 
        继续进行；
    } 
V 操作：
V（sem）{
    sem = sem + 1;
    if（sem ≤ 0）
        唤醒队列中的一个等待进程；
    else 
        继续进行；
    }
```
&emsp;&emsp;要用 P，V 操作实现进程同步，需要引进私用信号量。私用信号量只与制约进程和被制约进程有关，而不是与整组并发进程相关。与此相对，进程互斥使用的信号量为公用信号量。首先为各并发进程设置私用信号量，然后为私用信号量赋初值，最后利用 P，V 原语和私用信号量规定各进程的执行顺序。

#### 5. 前趋图
&emsp;&emsp;前趋图是一个由结点和有向边构成的有向无循环图。该图通常用于表现事务之间先后顺序的制约关系。图中的每个结点可以表示一个语句、一个程序段或是一个进程，结点间的有向边表示两个结点之间存在的前趋关系。

&emsp;&emsp;例如在计算机中，经常采用流水线方式执行指令，每一条指令都可以分解为取指、分析和执行三步。取指操作为 Ai，分析操作为 Bi 和执行操作为 Ci(i=1,2,3)。如下图所示为三个任务各程序段并发执行的前驱图。

[![前趋图示例](https://s3.ax1x.com/2020/12/28/rozRud.png)](https://imgchr.com/i/rozRud)

&emsp;&emsp;图中 A1 没有前趋结点，称为开始结点，它不受任何制约，可以直接执行；而 B1 与 A2只能在 A1 执行完成之后才能开始，而 B2 必须在 B1 与 A2 完成之后才能开始；C3 没有后继结点，称为终止结点。

&emsp;&emsp;在前趋图中，执行先后顺序的制约关系可分为两种：`直接制约`和`间接制约`。  
&emsp;&emsp;`直接制约`通常是指一个操作中，多个步骤之间的制约关系，也可以说是“同步的进程之间的制约关系”。如上图中的A1、B1、C1 是一条指令的取指、分析、执行的三个步骤，所以它们之间的关系是直接制约。  
&emsp;&emsp;`间接制约`通常是指多个操作之间相同步骤的制约关系，也可以说是“互斥的进程之间的制约关系”。如上图中的A1、A2、A3 之间就存在间接制约的关系。

#### 6．进程调度与死锁
&emsp;&emsp;进程调度即处理器调度（又称上下文转换），它的主要功能是确定在什么时候分配处理器，并确定分给哪一个进程，即让正在执行的进程改变状态并转入就绪队列的队尾，再由调度原语将就绪队列的队首进程取出，投入执行。

&emsp;&emsp;引起进程调度的原因有以下几类：
1. 正在执行的进程执行完毕。
2. 执行中的进程自己调用阻塞原语将自己阻塞起来进入睡眠状态。
3. 执行中的进程调用了 P 原语操作，从而因资源不足而阻塞；或调用 V 原语操作激活了等待资源的进程队列。
4. 在分时系统中，当一进程用完一个时间片。
5. 就绪队列中某进程的优先级变得高于当前执行进程的优先级，也将引起进程调度。

&emsp;&emsp;进程调度的方式有两类：`剥夺方式`与`非剥夺方式`。   
&emsp;&emsp;所谓非剥夺方式是指，一旦某个作业或进程占用了处理器，别的进程就不能把处理器从这个进程手中夺走，直到该进程自己因调用原语操作而进入阻塞状态，或时间片用完而让出处理机。  
&emsp;&emsp;剥夺方式是指，当就绪队列中有进程的优先级高于当前执行进程的优先级时，便立即发生进程调度，转让处理机。

&emsp;&emsp;进程调度的算法是服务于系统目标的策略，对于不同的系统与系统目标，常采用不同的调度算法：
1. 先来先服务（First Come and First Serverd，FCFS）调度算法  
&emsp;&emsp;又称先进先出（First Inand First Out，FIFO）。就绪队列按先来后到原则排队。
2. 优先数调度  
&emsp;&emsp;优先数反映了进程优先级，就绪队列按优先数排队。有两种确定优先级的方法，即`静态优先级`和`动态优先级`。静态优先级是指进程的优先级在进程开始执行前确定，执行过程中不变，而动态优先级则可以在进程执行过程中改变。
3. 轮转法（Round Robin）  
&emsp;&emsp;就绪队列按 FCFS 方式排队。每个进程执行一次占有处理器时间都不超过规定的时间单位（时间片）若超过，则自行释放自己所占有的 CPU 而排到就绪队列的末尾，等待下一次调度。同时，进程调度程序又去调度当前就绪队列中的第一个进程。

&emsp;&emsp;进程管理是操作系统的核心，在进程管理的实现中，如果设计不当，会出现一种尴尬的局面——死锁。当若干个进程互相竞争对方已占有的资源，无限期地等待，不能向前推进时会造成“死锁”。  
&emsp;&emsp;例如，P1 进程占有资源 R1，P2 进程占有资源 R2，这时，P1 又需要资源 R2，P2 也需要资源 R1，它们在等待对方占有的资源时，又不会释放自己占有的资源，因而使双方都进入了无限等待状态。  
&emsp;&emsp;死锁是系统的一种出错状态，它不仅会浪费大量的系统资源，甚至还会导致整个系统的崩溃，所以死锁是应该尽量预防和避免的。

1. 死锁条件   
&emsp;&emsp;产生死锁的主要原因是供共享的系统资源不足，资源分配策略和进程的推进顺序不当。系统资源既可能是可重复使用的永久性资源，也可能是消耗性的临时资源。  
&emsp;&emsp;产生死锁的必要条件是：`互斥条件`、`保持和等待条件`、`不剥夺条件`和`环路等待条件`。  
2. 解决死锁的策略   
&emsp;&emsp;处于死锁状态的进程不能继续执行但又占用了系统资源，从而阻碍其他作业的执行。   
&emsp;&emsp;解决死锁有两种策略：一种是在`死锁发生前采用的预防和避免策略`；另一种是`在死锁发生后采用的检测与恢复策略`。  
&emsp;&emsp;死锁的预防主要是通过打破死锁产生的 4 个必要条件之一来保证不会产生死锁。采用的死锁预防策略通常有资源的`静态分配法`或`有序分配法`，它们分别打破了资源动态分配条件和循环等待条件，因此不会发生死锁。但这样做会大大降低系统资源的利用率和进程之间的并行程度。  
&emsp;&emsp;死锁避免策略，则是在系统进行资源分配时，先执行一个死锁避免算法（典型的如银行家算法），以保证本次分配不会导致死锁发生。由于资源分配很频繁，因此死锁避免策略要耗费大量的 CPU 和时间。

&emsp;&emsp;实际上，系统出现死锁的概率很小，故从系统所花的代价上看，采用死锁发生后的检测与恢复策略要比采用死锁发生前的预防与避免策略代价小一些。

### 2.2.2 存储管理
&emsp;&emsp;存储管理主要是指对内存储器的管理，负责对内存的分配和回收、内存的保护和内存的扩充。存储管理的目的是尽量提高内存的使用效率。存储管理的机制经历了多次变迁，由以前的`单一连续区管理`到`分区存储管理`再发展为`段页式管理`。目前前两种技术已逐步被淘汰。

#### 1. 页式存储管理
&emsp;&emsp;分页的基本思想是把程序的逻辑空间和内存的物理空间按照同样的大小划分成若干页面，并以页面为单位进行分配。在页式存储管理中，系统中虚地址是一个有序对（页号，位移）。系统为每一个进程建立一个页表，其内容包括进程的逻辑页号与物理页号的对应关系、状态等。  
&emsp;&emsp;页式系统的动态地址转换是这样进行的：当进程运行时，其页表的首地址已在系统的动态地址转换机构中的基本地址寄存器中。执行的指令访问虚存地址（p，d）时，首先根据页号 p 查页表，由状态可知，这个页是否已经调入内存。若已调入内存，则得到该页的内存位置 p'，然后，与页内相对位移 d 组合，得到物理地址 r。如果该页尚未调入内存，则产生缺页中断，以装入所需的页，该过程如下图所示。

[![页式存储动态地址转换](https://s3.ax1x.com/2020/12/28/rTEYIH.png)](https://imgchr.com/i/rTEYIH)

&emsp;&emsp;页式虚拟存储管理是在页式存储管理的基础上实现虚拟存储器的。首先把作业信息作为副本存放在磁盘上，作业执行时，把作业信息的部分页面装入内存储器，作业执行时若所访问的页面已在内存中，则按页式存储管理方式进行地址转换，得到欲访问的内存绝对地址，若欲访问的页面不在内存中，则产生一个“缺页中断”，由操作系统把当前所需的页面装入内存储器中。  
&emsp;&emsp;为此，在装入作业时，就应在该作业的页表中指出哪些页已在内存储器中，哪些页还没有装入内存。可用一个标志位指示对应页是否在内存储器，可假设标志位为 1 表示该页在内存，而标志位为 0 表示该页尚未装入内存。为了能方便地从磁盘上找到作业信息的副本，故在页表中还可指出每一页副本在磁盘上的位置。

&emsp;&emsp;当内存中无空闲块时，为了装入一个页面而必须按某种算法从已在内存的页中选择一页，将它暂时调出内存，让出内存空间以存放所需装入的页面，这个工作称为“页面调度”。如何选择调出的页面是很重要的，如果采用了一个不合适的算法，就会出现这样的现象：刚被调出的页面又立即要用，因而又要把它装入，而装入不久又被选中调出，调出不久又被装入，如此反复，使调度非常频繁。这种现象称为`“抖动”`。一个好的调度算法应减少或避免抖动现象。  

&emsp;&emsp;常用的页面调度算法有：
1. 最优（OPT）算法  
&emsp;&emsp;选择不再使用或最远的将来才被使用的页，这是理想的算法，但是难以实现，常用于淘汰算法的比较。  
2. 随机（RAND）算法  
&emsp;&emsp;随机地选择被淘汰的页，开销小，但是可能选中立即就要访问的页。
3. 先进先出算法  
&emsp;&emsp;选择在内存驻留时间最长的页似乎合理，但可能淘汰掉频繁使用的页。另外，使用 FIFO 算法时，在未给予进程分配足够的页面数时，有时会出现给予进程的页面数增多，缺页次数反而增加的异常现象。  
&emsp;&emsp;FIFO 算法简单，易实现。可以把装入内存储器的那些页的页号按进入的先后顺序排成队列，每次总是调出队首的页，当装入一个新页后，把新页的页号排到队尾。
4. 最近最少使用（Least Recently Used，LRU）算法  
&emsp;&emsp;选择离当前时间最近的一段时间内使用得最少的页。这个算法的主要出发点是，如果某个页被访问了，则它可能马上就要被访问；反之，如果某个页长时间未被访问，则它在最近一段时间也不会被访问。

#### 2．段式存储管理
&emsp;&emsp;段式存储管理与页式存储管理相似。分段的基本思想是把用户作业按逻辑意义上有完整意义的段来划分，并以段为单位作为内外存交换的空间尺度。  
&emsp;&emsp;一个作业是由若干个具有逻辑意义的段（如主程序、子程序、数据段等）组成。分段系统中，容许程序（作业）占据内存中许多分离的分区。每个分区存储一个程序分段。这样每个作业需要几对界限地址寄存器，判定访问地址是否越界也就更困难了。在分段存储系统中常常利用存储保护键实现存储保护。分段系统中虚地址是一个有序对（段号，位移）。系统为每个作业建立一个段表，其内容包括段号、段长、内存起始地址和状态等。状态指出这个段是否已调入内存，即内存起始地址指出这个段，状态指出这个段的访问权限。

&emsp;&emsp;分段系统的动态地址转换是这样进行的：进程执行时，其段表的首地址已在基本地址寄存器中，执行的指令访问虚存（s，d）（取指令或取操作数）时，首先根据段号 s 查段表，若段已经调入内存，则得到该段的内存起始地址，然后与段内相对地址（段内偏移量 d）相加，得到实地址。如果该段尚未调入内存，则产生缺段中断，以装入所需要的段。

&emsp;&emsp;段式虚拟存储管理仍然以段式存储管理为基础，为用户提供比内存实际容量大的虚拟空间。段式虚拟存储管理把作业中的各个分段信息都保留在磁盘上，当作业可以投入执行时，做如下操作：
* 首先把当前需要的一段或几段装入内存。
* 作业执行时，如果要访问的段已经在内存，则按照“段式存储管理”中的方式进行地址转换；如果要访问的段不在内存中，则产生一个“缺段中断”，由操作系统把当前需要的段装入内存。

&emsp;&emsp;因此，在段表中应增设段是否在内存的标志以及各段在磁盘上的位置，已在内存中的段仍要指出该段在内存中的起始地址和占用内存区长度。  
&emsp;&emsp;作业执行要访问的段时，由硬件的地址转换机构查段表。若该段在内存中，则立即把逻辑地址转换成绝对地址；若该段不在内存中，则形成“缺段中断”，由操作系统处理这个中断。  
&emsp;&emsp;处理的办法是:查内存分配表，找出一个足够大的连续区以容纳该分段，如果找不到足够大的连续区则检查空闲区的总和，若空闲区总和能满足该段要求，那么进行适当移动将分散的空闲区集中；若空闲区总和不能满足该段要求，可把内存中的一段或几段调出，然后把当前要访问的段装入内存中。段被移动、调出和装入后都要对段表中的相应表目做修改。新的段被装入后应让作业重新执行被中断的指令，这时就能找到要访问的段，也可以继续执行下去。

#### 3．段页式存储管理
&emsp;&emsp;段页式管理是段式和页式两种管理方法结合的产物，综合了段式组织与页式组织的特点，根据程序模块分段，段内再分页，内存被分划成定长的页。段页式系统中虚地址形式是（段号、页号、页内偏移），如下图所示。

[![段页式系统的虚地址形式](https://s3.ax1x.com/2020/12/28/rTmG6I.png)](https://imgchr.com/i/rTmG6I)

&emsp;&emsp;系统为每个进程建立一个段表，为每个段建立一个页表。段页式管理采用段式分配、页式使用的方法，便于动态连接和存储的动态分配。这种存储管理能提高内存空间的利用率。  
&emsp;&emsp;段式虚拟管理还是以段为单位分配内存空间，整段的调出、装入，有时还要移动，这些都增加了系统的开销。如果按段页式存储管理的方式，把每一段再分成若干页面，那么，每一段不必占用连续的存储空间；甚至当内存块不够时，可只将一段中的部分页面装入内存，这种管理方式称为“段页式虚拟存储管理”。  
&emsp;&emsp;段页式虚拟存储管理为每一个装入内存的作业建立一张段表，还要为每一段建立页表。段表中指出该段的页表存放位置及长度，页表中应指出该段的各页在磁盘上的位置以及页是否在内存中，若在内存中则填上占用的内存块号。作业执行时按段号查段表，找到相应的页表再根据页号查页表，由标志位判定该页是否已在内存，若是，则进行地址转换；否则进行页面调度。地址转换过程如下图所示。

[![段页式存储地址转换过程](https://s3.ax1x.com/2020/12/28/rTmcn0.png)](https://imgchr.com/i/rTmcn0)

&emsp;&emsp;段页式虚拟存储管理结合了段式和页式的优点，但增加了设置表格（段表、页表）和查表等开销，段页式虚拟存储器一般只在大型计算机系统中使用。

<!-- 

### 1.1.3 数据表示
1. 原码  
如果机器字长为n，那么原码的定义如下：  
若X是纯整数，则当X是非负数时原码即为X，当X是负数是原码为2^(n-1) + |X|。  
若X是纯小数，则当X是非负数时原码即为X，当X是负数时原码为2^0 + |X|。  
`负数首位为1`
2. 反码
如果机器字长为n，那么反码的定义如下：  
若X是纯整数，则当X是非负数时原码即为X，当X是负数是原码为2^n - 1 + |X|。  
若X是纯小数，则当X是非负数时原码即为X，当X是负数时原码为2-2^-(n-1) + |X|。  
`负数按位取反`
3. 补码
如果机器字长为n，那么补码的定义如下：  
若X是纯整数，则当X是非负数时原码即为X，当X是负数是原码为2^n + |X|。  
若X是纯小数，则当X是非负数时原码即为X，当X是负数时原码为2 + |X|。 
`负数按位取反+1`
4. 移码
在机器字长为n，偏移量为2^(n-1)的情况下，纯整数的移码为2^(n-1)+X,纯小数的移码为1+X。`补码符号位取反即可得到移码`  

### 1.1.4 校验码
计算机通常使用校验码的方法来检测传送的数据是否出问题。  
`码距`:一个编码系统中任意两个合法编码之间至少有多少个二进制位不同  
1. 奇偶校验码  
通过在编码中增加一位校验位来使编码中1的个数为奇数（奇校验）或者偶数（偶校验），从而使码距变为2。  
常见的有：`水平奇偶校验码`，`垂直奇偶校验码`，`水平垂直校验码`
2. 海明码
海明码利用奇偶性来检错和纠错。在数据位之间的特定位置上插入K个校验位，通过扩大码距来实现检错和纠错。
3. 循环冗余校验码
利用多项式为K个数据位产生R个校验位，编码长度K+R记为N，N为CRC码的字长，又称为(n,k)码。   -->